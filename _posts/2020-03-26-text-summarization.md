---
layout: single
author_profile: true
read_time: true
comments: true
share: true
related: true
title: text summarization
---

파이썬에서의 텍스트 요약 : 추출 대 추상 기법 재검토

이 블로그는 텍스트 요약에 대한 간단한 소개이며 현재 환경에 대한 실질적인 요약으로 사용될 수 있습니다. RaRe Incubator 프로그램 의 3 명의 학생으로 구성된 팀 이이 도메인의 기존 알고리즘 및 Python 도구를 실험 한 방법을 설명 합니다.

LexRank, LSA, Luhn 및 Gensim의 기존 TextRank 요약 모듈 과 같은 최신 추출 방법 을 51 개의 기사 요약 쌍 의 오 피노 시스 데이터 세트 에서 비교 합니다. 또한 Tensorflow의 Text Summarization 알고리즘을 사용 하는 추상 기술을 사용해 보았지만 하드웨어 요구가 매우 높기 때문에 (7000 GPU 시간, ~ 3 천만 달러의 클라우드 크레딧) 좋은 결과를 얻지 못했습니다 .


왜 텍스트 요약입니까?
푸시 알림과 기사 요약이 점점 더 많은 관심을 끌고 있기 때문에 긴 텍스트에 대한 지능적이고 정확한 요약 을 생성하는 작업은 업계의 문제 일뿐만 아니라 대중적인 연구가되었습니다.

텍스트 요약에는 추출 및 추상 이라는 두 가지 기본 접근 방식이 있습니다 . 전자는 원본 텍스트에서 단어와 단어 문구를 추출하여 요약을 만듭니다. 후자는 더 많은 사람과 유사한 요약을 생성하기 위해 내부 언어 표현을 배우고 원본 텍스트의 의도를 설명합니다.



텍스트 요약에는 추출 및 추상 이라는 두 가지 기본 접근 방식이 있습니다 .

추출 텍스트 요약
먼저, 오늘날 존재하는 텍스트 요약을위한 인기있는 알고리즘 및 구현에 대한 간단한 설명 :

Gensim의 텍스트 요약
gensim.summarization이 모듈 은 Mihalcea 등 의 논문 에서 가중치 그래프를 기반으로하는 감독되지 않은 알고리즘 인 TextRank를 구현 합니다. 다른 인큐베이터 학생 인 Olavur Mortensen이 추가했습니다 .이 블로그의 이전 게시물 을 참조하십시오 . Google이 웹 페이지 순위를 지정하는 데 사용 하는 인기있는 PageRank 알고리즘 위에 구축되었습니다 . TextRank는 다음과 같이 작동합니다.

텍스트를 사전 처리하십시오. 중지 단어를 제거하고 나머지 단어를 제거하십시오.
정점이 문장 인 그래프를 만듭니다.
모든 문장을 다른 모든 문장에 연결하십시오. 가장자리의 무게는 두 문장이 얼마나 비슷한 지입니다.
그래프에서 PageRank 알고리즘을 실행하십시오.
PageRank 점수가 가장 높은 정점 (문장)을 선택하십시오.
원본 TextRank에서 두 문장 사이의 모서리 가중치는 두 문장 모두에 나타나는 단어의 백분율입니다. Gensim의 TextRank는 Okapi BM25 함수를 사용 하여 문장이 얼마나 유사한 지 확인합니다. Barrios et al. 의 논문 에서 개선되었습니다 . .

파이 티저
PyTeaser 는 추출 텍스트 요약을위한 휴리스틱 접근 방식 인 Scala 프로젝트 TextTeaser 의 Python 구현입니다 .

TextTeaser는 모든 문장에 점수를 연결합니다. 이 점수는 해당 문장에서 추출 된 기능의 선형 조합입니다. TextTeaser가 보는 기능은 다음과 같습니다.

titleFeature : 문서의 제목과 문장에 공통적 인 단어 수.
sentenceLength : TextTeaser의 저자는 단어의 개수로 요약의 이상적인 길이를 나타내는 상수 "이상적"(값 20)을 정의했습니다. sentenceLength 는이 값으로부터 정규화 된 거리로 계산됩니다.
sentencePosition : 정규화 된 문장 번호 (문 목록의 위치).
keywordFrequency : bag-of-words 모델의 용어 빈도 (중지 단어 제거 후).
요약을위한 문장 기능에 대한 자세한 내용 은 Jagadeesh et al .의 문장 추출 기반 단일 문서 요약을 참조하십시오 .

PyTextRank
PyTextRank 는 원본 TextRank 알고리즘을 파이썬으로 구현하여 형태소 분석 대신 lemmatization 사용, 품사 태그 지정 및 명명 된 엔티티 해상도 통합, 기사에서 주요 문구를 추출하고이를 기반으로 요약 문장을 추출하는 등 몇 가지 기능이 향상되었습니다. 기사의 요약과 함께 PyTextRank는 기사에서 의미있는 주요 문구를 추출합니다. PyTextRank는 네 단계로 작동하며 각 단계는 다음 단계로 출력됩니다.

첫 번째 단계에서는 품사 태그 및 lemmatization이 문서의 모든 문장에 대해 수행됩니다.
두 번째 단계에서는 주요 문구가 개수와 함께 추출되어 정규화됩니다.
문장과 주요 문구 사이의 자카드 거리를 근사하여 각 문장에 대한 점수를 계산합니다.
가장 중요한 문장과 주요 문구를 기반으로 문서를 요약합니다.
룬 알고리즘
1958 년에 출판 된이 알고리즘 [ PDF ]은 문서에서 자주 발생하는 "유의 한"단어와 중요하지 않은 단어로 인한이 단어들 사이의 선형 거리를 고려하여 요약 추출에 대한 문장 순위를 매 깁니다.

LexRank
LexRank 는 TextRank 와 유사한 비 감독 그래프 기반 접근 방식입니다. LexRank는 두 문장 사이의 유사성 측정법으로 IDF 수정 코사인을 사용합니다. 이 유사성은 두 문장 사이의 그래프 가장자리의 가중치로 사용됩니다. LexRank는 또한 지능적인 사후 처리 단계를 통합하여 요약을 위해 선택된 상위 문장이 서로 너무 유사하지 않도록합니다.

LexRank Vs에 대한 추가 정보. TextRank는 여기 에서 찾을 수 있습니다 .

텍스트 요약의 LSA (잠재적 의미 분석)
LSA는 중요한 정보 손실없이 데이터를보다 낮은 차원의 공간으로 투사합니다. 이 공간 분해 연산을 해석하는 한 가지 방법은 단일 벡터가 말뭉치에서 반복되는 단어 조합 패턴을 캡처하고 나타낼 수 있다는 것입니다. 특이 값의 크기는 문서에서 패턴의 중요성을 나타냅니다.

특이 벡터 및 특이 값과 같은 용어가 익숙하지 않은 경우이 자습서를 사용하는 것이 좋습니다. 이 자습서에서는 유익하고 순진한 Python 구현을 포함하여 LSA 이론을 다룹니다 (강건하고 빠른 구현을 위해서는 gensim 에서 LSA 사용 ).

텍스트 요약 품질을 평가하는 방법은 무엇입니까?
ROUGE-N 측정 항목
LexRank, Luhn 및 LSA 방법의 경우  이러한 알고리즘을 구현 하는 Sumy 요약 라이브러리를 사용했습니다. ROUGE-1 메트릭을 사용하여 논의 된 기술을 비교했습니다.

루즈 -N 은 모델과 금 요약 사이의 단어 N- 그램 측정 값입니다.

구체적으로, 이는 모델 및 금 요약에서 발생하는 N- 그램 문구 수와 금 요약에 존재하는 모든 N- 그램 문구 수의 비율입니다.

이것을 해석하는 또 다른 방법은 모델 요약에 금 요약에서 몇 개의 N- 그램이 나타나는지를 측정하는 리콜 값입니다.

일반적으로 요약 평가의 경우 ROUGE-1 및 ROUGE-2 (때로는 금과 모델 요약이 실제로 긴 경우 ROUGE-3) 메트릭 만 사용됩니다. 이론적으로 N을 늘리면 N- 그램의 길이가 증가합니다. 금과 모델 요약에서 완전히 일치해야하는 단어 구.

예를 들어, 의미 적으로 유사한 두 개의 문구“ 사과 바나나 ”와“ 사과 사과 ”를 고려하십시오. ROUGE-1을 사용하는 경우 유니 그램 만 고려하며 두 구 모두 동일합니다. 그러나 ROUGE-2를 사용하는 경우 2 워드 문구를 사용하므로 " 사과 바나나 "는 " 사과 사과 "와 다른 단일 엔티티 가되어 "미스"및 낮은 평가 점수로 이어집니다.

예:

금 요약 : 좋은 식단에는 사과와 바나나가 있어야합니다.
모델 사과와 바나나는 좋은 식단을 유지해야합니다.

ROUGE-1을 사용하면 점수는 7/8 = 0.875입니다.

ROUGE-2의 경우 4/7 = ~ 0.57입니다.

위의 비율은 알고리즘이 모든 관련 정보 세트에서 추출 할 수있는 관련 정보의 양으로 해석 될 수 있으며, 이는 정확하게 리콜의 정의이므로 루즈는 리콜 기반입니다.

점수 계산 방법의 더 많은 예는이 요지에 있습니다.

BLEU 측정 항목
BLEU 메트릭은 기계 번역 평가에 광범위하게 사용되는 수정 된 정밀도 형식입니다.

정밀도는 금과 모델 번역 / 요약에서 동시에 발생하는 단어 수와 모델 요약의 단어 수의 비율입니다. ROUGE와 달리 BLEU는 가중 평균을 취하여 가변 길이 구 (Unigram, Bigram, Trigram 등)를 직접 처리합니다.

실제 메트릭은 모델의 변환 / 요약에 반복되는 관련 정보가 포함되어있을 때 문제를 피하기 위해 수정 된 정밀도입니다.

예:

금 요약 : 좋은 식단에는 사과와 바나나가 있어야합니다.
모델 요약 : 사과와 바나나는 좋은 식단을 유지해야합니다.

유니 그램만을 고려하여 BLEU 점수를 사용하는 경우, 즉 다른 모든 N- 그램에 대해 유니 그램의 무게가 1과 0 인 경우 BLEU에 대한 비율은 7/9 = 0.778로 계산됩니다.

유니 그램 및 빅 그램에 대한 가중치 [0.6, 0.4]의 경우 비율은 0.6 * (7/9) + 0.4 * (4/8) = 0.667이됩니다.

수정 된 N- 그램 정밀도의 BLEU
수정 된 N- 그램 정밀도의 주요 직관은 참조 문구 / 단어가 모델 요약에서 식별되면 소진 된 것으로 간주해야한다는 것입니다. 이 아이디어는 모델 요약에서 반복 / 과잉 생성 된 단어의 문제를 해결합니다.

수정 된 N- 그램 정밀도는 단일 참조에서 단어 / 문구가 발생하는 최대 횟수를 먼저 찾아서 계산합니다. 이 카운트는 해당 단어 / 구문 의 최대 참조 카운트가됩니다 . 그런 다음 각 모델 단어 / 문구의 총 개수를 최대 참조 횟수로 자르고 모델 변환 / 요약에서 각 단어에 대해 잘린 개수를 더한 다음 모델 변환 / 요약에서 총 단어 / 구문 수로 합계를 나눕니다.

BLEU에 대한 논문 링크 (위 참조)에는 수정 된 N-gram 정밀도에 대한 좋은 예가 있습니다.

TL; DR : ROUGE 및 BLEU 점수가 클수록 요약이 더 좋습니다.

데이터 세트
51 기사 의 오 피노 시스 데이터 세트 를 사용하여 비교를 수행 하였다 . 각 기사는 iPod의 배터리 수명 등과 같은 제품 기능에 관한 것이며 해당 제품을 구입 한 고객의 리뷰 모음입니다. 데이터 세트의 각 기사에는 5 개의 수동으로 작성된 "골드"요약이 있습니다. 일반적으로 5 개의 금 요약은 다르지만 5 번 반복 된 동일한 텍스트 일 ​​수도 있습니다.

모델 파라미터
Gensim TextRank의 경우 출력 요약의 단어 수, word_count는 75로 설정되었습니다.
Sumy-LSA 및 Sumy-Lex_rank의 경우 출력 요약 (sentence_count)의 문장 수는 2로 설정되었습니다.